{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.metrics import confusion_matrix\n",
    "from  sklearn.metrics import accuracy_score\n",
    "from  sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION ALOGORITHM 1: NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network is a supervised learning algortihtm which means that we provide it with input data containing the independent variables and the output data that contain dependent variable.\n",
    "\n",
    "Independent variables are:\n",
    "- GRE Scores( out of 340)\n",
    "- TOEFL Scores (out of 120)\n",
    "- University Rating ( out of 5)\n",
    "- Statement of Purpose (out of 5)\n",
    "- Letter of Recommendation Strength (out of 5)\n",
    "- Undergraduate GPA (out of 10)\n",
    "- Research Experience ( either 0 or 1)\n",
    "\n",
    "\n",
    "Dependent varibale:\n",
    "- Chance of acceptance (feature that we would like to predict, 1 for accepted and 0 for rejected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GREScore</th>\n",
       "      <th>TOEFLScore</th>\n",
       "      <th>UniversityRating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>ChanceOfAdmit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GREScore  TOEFLScore  UniversityRating  SOP  LOR   CGPA  \\\n",
       "0             1       337         118                 4  4.5   4.5  9.65   \n",
       "1             2       324         107                 4  4.0   4.5  8.87   \n",
       "2             3       316         104                 3  3.0   3.5  8.00   \n",
       "3             4       322         110                 3  3.5   2.5  8.67   \n",
       "4             5       314         103                 2  2.0   3.0  8.21   \n",
       "..          ...       ...         ...               ...  ...   ...   ...   \n",
       "395         396       324         110                 3  3.5   3.5  9.04   \n",
       "396         397       325         107                 3  3.0   3.5  9.11   \n",
       "397         398       330         116                 4  5.0   4.5  9.45   \n",
       "398         399       312         103                 3  3.5   4.0  8.78   \n",
       "399         400       333         117                 4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  ChanceOfAdmit  \n",
       "0           1           0.92  \n",
       "1           1           0.76  \n",
       "2           1           0.72  \n",
       "3           1           0.80  \n",
       "4           0           0.65  \n",
       "..        ...            ...  \n",
       "395         1           0.82  \n",
       "396         1           0.84  \n",
       "397         1           0.91  \n",
       "398         0           0.67  \n",
       "399         1           0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'Admission_Predict.csv' \n",
    "df = pandas.read_csv(data_file) #reading our data file\n",
    "\n",
    "df #our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSING AND PROCESSING OUR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  , 337.  , 118.  , ...,   9.65,   1.  ,   0.92],\n",
       "       [  2.  , 324.  , 107.  , ...,   8.87,   1.  ,   0.76],\n",
       "       [  3.  , 316.  , 104.  , ...,   8.  ,   1.  ,   0.72],\n",
       "       ...,\n",
       "       [398.  , 330.  , 116.  , ...,   9.45,   1.  ,   0.91],\n",
       "       [399.  , 312.  , 103.  , ...,   8.78,   0.  ,   0.67],\n",
       "       [400.  , 333.  , 117.  , ...,   9.66,   1.  ,   0.95]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values #converting our dataframe into an array\n",
    "dataset#our array of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature data: \n",
      " [[337.   118.     4.   ...   4.5    9.65   1.  ]\n",
      " [324.   107.     4.   ...   4.5    8.87   1.  ]\n",
      " [316.   104.     3.   ...   3.5    8.     1.  ]\n",
      " ...\n",
      " [330.   116.     4.   ...   4.5    9.45   1.  ]\n",
      " [312.   103.     3.   ...   4.     8.78   0.  ]\n",
      " [333.   117.     4.   ...   4.     9.66   1.  ]]\n",
      "labelled data: \n",
      " [0.92 0.76 0.72 0.8  0.65 0.9  0.75 0.68 0.5  0.45 0.52 0.84 0.78 0.62\n",
      " 0.61 0.54 0.66 0.65 0.63 0.62 0.64 0.7  0.94 0.95 0.97 0.94 0.76 0.44\n",
      " 0.46 0.54 0.65 0.74 0.91 0.9  0.94 0.88 0.64 0.58 0.52 0.48 0.46 0.49\n",
      " 0.53 0.87 0.91 0.88 0.86 0.89 0.82 0.78 0.76 0.56 0.78 0.72 0.7  0.64\n",
      " 0.64 0.46 0.36 0.42 0.48 0.47 0.54 0.56 0.52 0.55 0.61 0.57 0.68 0.78\n",
      " 0.94 0.96 0.93 0.84 0.74 0.72 0.74 0.64 0.44 0.46 0.5  0.96 0.92 0.92\n",
      " 0.94 0.76 0.72 0.66 0.64 0.74 0.64 0.38 0.34 0.44 0.36 0.42 0.48 0.86\n",
      " 0.9  0.79 0.71 0.64 0.62 0.57 0.74 0.69 0.87 0.91 0.93 0.68 0.61 0.69\n",
      " 0.62 0.72 0.59 0.66 0.56 0.45 0.47 0.71 0.94 0.94 0.57 0.61 0.57 0.64\n",
      " 0.85 0.78 0.84 0.92 0.96 0.77 0.71 0.79 0.89 0.82 0.76 0.71 0.8  0.78\n",
      " 0.84 0.9  0.92 0.97 0.8  0.81 0.75 0.83 0.96 0.79 0.93 0.94 0.86 0.79\n",
      " 0.8  0.77 0.7  0.65 0.61 0.52 0.57 0.53 0.67 0.68 0.81 0.78 0.65 0.64\n",
      " 0.64 0.65 0.68 0.89 0.86 0.89 0.87 0.85 0.9  0.82 0.72 0.73 0.71 0.71\n",
      " 0.68 0.75 0.72 0.89 0.84 0.93 0.93 0.88 0.9  0.87 0.86 0.94 0.77 0.78\n",
      " 0.73 0.73 0.7  0.72 0.73 0.72 0.97 0.97 0.69 0.57 0.63 0.66 0.64 0.68\n",
      " 0.79 0.82 0.95 0.96 0.94 0.93 0.91 0.85 0.84 0.74 0.76 0.75 0.76 0.71\n",
      " 0.67 0.61 0.63 0.64 0.71 0.82 0.73 0.74 0.69 0.64 0.91 0.88 0.85 0.86\n",
      " 0.7  0.59 0.6  0.65 0.7  0.76 0.63 0.81 0.72 0.71 0.8  0.77 0.74 0.7\n",
      " 0.71 0.93 0.85 0.79 0.76 0.78 0.77 0.9  0.87 0.71 0.7  0.7  0.75 0.71\n",
      " 0.72 0.73 0.83 0.77 0.72 0.54 0.49 0.52 0.58 0.78 0.89 0.7  0.66 0.67\n",
      " 0.68 0.8  0.81 0.8  0.94 0.93 0.92 0.89 0.82 0.79 0.58 0.56 0.56 0.64\n",
      " 0.61 0.68 0.76 0.86 0.9  0.71 0.62 0.66 0.65 0.73 0.62 0.74 0.79 0.8\n",
      " 0.69 0.7  0.76 0.84 0.78 0.67 0.66 0.65 0.54 0.58 0.79 0.8  0.75 0.73\n",
      " 0.72 0.62 0.67 0.81 0.63 0.69 0.8  0.43 0.8  0.73 0.75 0.71 0.73 0.83\n",
      " 0.72 0.94 0.81 0.81 0.75 0.79 0.58 0.59 0.47 0.49 0.47 0.42 0.57 0.62\n",
      " 0.74 0.73 0.64 0.63 0.59 0.73 0.79 0.68 0.7  0.81 0.85 0.93 0.91 0.69\n",
      " 0.77 0.86 0.74 0.57 0.51 0.67 0.72 0.89 0.95 0.79 0.39 0.38 0.34 0.47\n",
      " 0.56 0.71 0.78 0.73 0.82 0.62 0.96 0.96 0.46 0.53 0.49 0.76 0.64 0.71\n",
      " 0.84 0.77 0.89 0.82 0.84 0.91 0.67 0.95]\n"
     ]
    }
   ],
   "source": [
    "#Here we split our dataset into input features X and the feature we wish to predict\n",
    "\n",
    "X = dataset[:,1:8] #here we remove the first column and take the remaining dataset with the exception of the feture we want to predict\n",
    "Y_ = dataset[:,8] #get our feature that we need to predict\n",
    "\n",
    "print(\"feature data: \\n\", X)\n",
    "print(\"labelled data: \\n\",Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERTING ACCEPTANCE CHANCE TO CLASSIFICATION THROUGH ROUNDING UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [] #list to store new rounded up acceptance chance column values\n",
    "threshold = 0.5 # our threshold for rounding\n",
    "\n",
    "#convert values to 0 = not accepted and 1 = accepted\n",
    "\n",
    "for i in Y_: #loop through label data \n",
    "    if i < threshold:\n",
    "        i = 0 #set to 0 \n",
    "        Y.append(i) #store updated values\n",
    "    \n",
    "    else:\n",
    "        i = 1  #otherwise set to 1\n",
    "        Y.append(i) #store updated values\n",
    "Y = np.array(Y)\n",
    "Y = Y.reshape(X.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X scaled: \n",
      " [[0.94       0.92857143 0.75       ... 0.875      0.91346154 1.        ]\n",
      " [0.68       0.53571429 0.75       ... 0.875      0.66346154 1.        ]\n",
      " [0.52       0.42857143 0.5        ... 0.625      0.38461538 1.        ]\n",
      " ...\n",
      " [0.8        0.85714286 0.75       ... 0.875      0.84935897 1.        ]\n",
      " [0.44       0.39285714 0.5        ... 0.75       0.63461538 0.        ]\n",
      " [0.86       0.89285714 0.75       ... 0.75       0.91666667 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#here we process our data to make sure that the scale of the input features are similar\n",
    "#we do this to avoid difficulties for the initialization of the neutral network\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X) #Scaling the dataset so that all input features lie between 0 and 1 inclusive\n",
    "print(\"X scaled: \\n\",X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIVIDING THE DATA\n",
    "\n",
    "7 features\n",
    "\n",
    "- X-training data = 204 (60%)\n",
    "- X- validation data = 68 (20%)\n",
    "- X- testing data = 68 (20%)\n",
    "\n",
    "Chance of admission feature\n",
    "\n",
    "- Y-training data = 204 (60%)\n",
    "- Y- validation data = 68 (20%)\n",
    "- Y- testing data = 68 (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Shape of training data:  (240, 7)\n",
      "Shape of training label:  (240, 1)\n",
      "Shape of validation data:  (80, 7)\n",
      "Shape of validation label:  (80, 1)\n",
      "Shape of testing data:  (80, 7)\n",
      "Shape of testing label:  (80, 1)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# validation and testing takes 40% of the original data and training takes 60% and randomizing\n",
    "X_training,X_validation_test, Y_training_label, Y_validation_test =  train_test_split(X_scale, Y, test_size = 0.4,random_state = 2) # here we split trainig data and validation/testing data into two\n",
    "\n",
    "#spliting validation and testing and randomizing\n",
    "\n",
    "X_validation, X_testing, Y_validation_label, Y_testing_label = train_test_split(X_validation_test,Y_validation_test,test_size = 0.5,random_state = 2)\n",
    "\n",
    "#standardize the dataset\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Shape of training data: \",X_training.shape)\n",
    "print(\"Shape of training label: \",Y_training_label.shape)\n",
    "print(\"Shape of validation data: \",X_validation.shape)\n",
    "print(\"Shape of validation label: \",Y_validation_label.shape)\n",
    "print(\"Shape of testing data: \",X_testing.shape)\n",
    "print(\"Shape of testing label: \",Y_testing_label.shape)\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.............................................\n",
      "confusion matrix\n",
      "--------\n",
      "|6 | 16|\n",
      "|1 | 217|\n",
      "--------\n",
      "accuracy: :92.91666666666667%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation.............................................\n",
      "confusion matrix\n",
      "--------\n",
      "|3 | 6|\n",
      "|3 | 68|\n",
      "--------\n",
      "accuracy: :88.75%\n",
      "Testing.............................................\n",
      "confusion matrix\n",
      "--------\n",
      "|0 | 2|\n",
      "|0 | 78|\n",
      "--------\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :0\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :0\n",
      "Predicted values : :1 | Actual values : :1\n",
      "accuracy: :97.5%\n",
      "Mean Square Error = 0.025\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet():\n",
    "        #class takes in list that stores our network architecture, learning rate and iterations\n",
    "        # layers[7 input features, 8 nodes for hidden layer, 1 output]\n",
    "        \n",
    "        def __init__(self, layers = [7,20,1], l_rate = 0.001, iter = 100):\n",
    "            self.X = None\n",
    "            self.Y = None\n",
    "            self.params = {} #dictionary to store weights\n",
    "            self.loss = []\n",
    "            self.layers = layers\n",
    "            self.l_rate = l_rate\n",
    "            self.iter = iter\n",
    "        \n",
    "        #initializes weights for the network\n",
    "        #we use unifrom distribution for our weights and store them in the params dictionary \n",
    "        def init_weights(self):\n",
    "            \n",
    "            np.random.seed(1) #seed that random number of generator\n",
    "            self.params['W1'] = np.random.randn(self.layers[0], self.layers[1]) #array of shape(7,20)\n",
    "            self.params['b1'] = np.random.randn(self.layers[1],) #vector of size 20\n",
    "            self.params['W2'] = np.random.randn(self.layers[1], self.layers[2]) #array of shape(20,1)\n",
    "            self.params['b2'] = np.random.randn(self.layers[2],)#vector of size 1, the output\n",
    "            \n",
    "        #here we gonna have a function for loss function\n",
    "        # it measures how good our neural network is predicting so that it can adjust the weights\n",
    "        \n",
    "        def entropy_loss(self,y, y_hat):\n",
    "            n = len(y) #number of samples\n",
    "            loss = -1/n * (np.sum(np.multiply(np.log(y_hat),y) + np.multiply((1 - y), np.log(1 - y_hat))))\n",
    "            return loss\n",
    "            \n",
    "        #for our network we will use an activation function (ReLU function) for hidden layer\n",
    "        #This function compares a value with zero then return the value passed to if if it is greater that zero\n",
    "        #It will perform threshold operation to each value input\n",
    "        \n",
    "        def ReLU(self,Z):\n",
    "            return np.maximum(0,Z)\n",
    "        \n",
    "        #we will also use sigmoid function for our ouput layer\n",
    "        #takes in input value and squashes it to a real valued output between 0 and 1\n",
    "        \n",
    "        def sigmoid(self, Z):\n",
    "            return 1.0/(1.0 + np.exp(-Z))\n",
    "        \n",
    "            \n",
    "        #forward propagation\n",
    "        def forward_prop(self):\n",
    "            \n",
    "            #perfom all dot product and addition usinf weights and biases\n",
    "            \n",
    "            Z1 = self.X.dot(self.params['W1']) + self.params['b1']  #weighted sum between input and first layer's weights and add bias\n",
    "            A1 = self.ReLU(Z1) # passing Z1 into activation function\n",
    "            Z2 = A1.dot(self.params['W2']) + self.params['b2'] #weighted sum between output of A1 and second layer's weights and add bias\n",
    "            yhat = self.sigmoid(Z2) #passing Z2 into activation function\n",
    "            loss = self.entropy_loss(self.y,yhat) #loss between predicted output and sigmoid resulyHat\n",
    "            \n",
    "            #save all calculated parameters\n",
    "            \n",
    "            self.params['Z1'] = Z1\n",
    "            self.params['Z2'] = Z2\n",
    "            self.params['A1'] = A1\n",
    "            \n",
    "            return yhat,loss #return predicted value and loss we will use in backpropagation\n",
    "        \n",
    "        #backpropagtion to train our network by updating weights and biases\n",
    "            \n",
    "\n",
    "        def back_prop(self,yhat):\n",
    "\n",
    "            #compute derivative\n",
    "            def dReLU(x):\n",
    "                x[x <=0 ] = 0\n",
    "                x[x > 0 ] = 1\n",
    "                return x\n",
    "\n",
    "         #dl_wrt means loss with respect to \n",
    "            dl_wrt_yhat = -(np.divide(self.y,yhat) - np.divide((1 - self.y),(1-yhat))) \n",
    "            dl_wrt_sig = yhat * (1-yhat)\n",
    "            dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "            dl_wrt_A1 = dl_wrt_z2.dot(self.params['W2'].T)\n",
    "            dl_wrt_w2 = self.params['A1'].T.dot(dl_wrt_z2)\n",
    "            dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0)\n",
    "\n",
    "            dl_wrt_z1 = dl_wrt_A1 * dReLU(self.params['Z1'])\n",
    "            dl_wrt_w1 = self.X.T.dot(dl_wrt_z1)\n",
    "            dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0)\n",
    "\n",
    "            #update weights and bias\n",
    "\n",
    "            self.params['W1'] = self.params['W1'] - self.l_rate * dl_wrt_w1 \n",
    "            self.params['b1'] = self.params['b1'] - self.l_rate * dl_wrt_b1\n",
    "            self.params['W2'] = self.params['W2'] - self.l_rate * dl_wrt_w2 \n",
    "            self.params['b2'] = self.params['b2'] - self.l_rate * dl_wrt_b2\n",
    "\n",
    "        #function for predicting\n",
    "\n",
    "            \n",
    "        def predicting(self, X):\n",
    "            \n",
    "            Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "            A1 = self.ReLU(Z1)\n",
    "            Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "            pred = self.sigmoid(Z2)\n",
    "            return np.round(pred)              \n",
    "\n",
    "        #function for marmalising y_hat\n",
    "        \n",
    "        def normalize(self, arr):\n",
    "            new_arr = []\n",
    "            threshold = 0.5 # our threshold for rounding\n",
    "\n",
    "            #convert values to 0 = not accepted and 1 = accepted\n",
    "\n",
    "            for i in arr: #loop through label data \n",
    "                if i < threshold:\n",
    "                    i = 0 #set to 0 \n",
    "                    new_arr.append(i) #store updated values\n",
    "\n",
    "                else:\n",
    "                    i = 1  #otherwise set to 1\n",
    "                    new_arr.append(i) #store updated values\n",
    "            new_arr = np.array(new_arr)\n",
    "            return new_arr\n",
    "        \n",
    "        #function for training\n",
    "\n",
    "        def training(self, X, y):\n",
    "            \n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "            for i in range(self.iter):\n",
    "                yhat,loss = self.forward_prop() \n",
    "                self.loss.append(loss)\n",
    "                self.back_prop(yhat)\n",
    "\n",
    "            return yhat\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "        def plotting_loss(self):\n",
    "\n",
    "            plt.plot(self.loss)\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"log-loss\")\n",
    "            plt.title(\"Loss curve for training\")\n",
    "            plt.show()\n",
    "            \n",
    "        def confusion_mat(self, actual, predicted):\n",
    "            cm = confusion_matrix(actual,np.round(predicted))\n",
    "            print(\"confusion matrix\")\n",
    "            print(\"--------\")\n",
    "            print(\"|\" + str(cm[0][0]) + \" | \" + str(cm[0][1]) + \"|\")\n",
    "            print(\"|\" + str(cm[1][0]) + \" | \" + str(cm[1][1]) + \"|\")\n",
    "            print (\"--------\")\n",
    "            \n",
    "        def error(self,actual,predicted):\n",
    "            error = mean_squared_error(predicted,actual)\n",
    "            \n",
    "            return error\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "       \n",
    "        \n",
    "        def print_values(self, actual, predicted):\n",
    "            \n",
    "            for i in range(1,len(actual)):\n",
    "                print(\"Predicted values : :{}\".format(predicted[i]) + \" | \" + \"Actual values : :{}\".format(actual[i][0]))\n",
    "            \n",
    "            \n",
    "            \n",
    "NN = NeuralNet()\n",
    "\n",
    "\n",
    "\n",
    "print('Training.............................................')\n",
    "yhat = NN.training(X_training,Y_training_label)\n",
    "yhat = NN.normalize(yhat)\n",
    "NN.confusion_mat(Y_training_label,yhat)\n",
    "print(\"accuracy: :{}\".format(accuracy_score(Y_training_label,yhat)*100) +\"%\")\n",
    "NN.plotting_loss()\n",
    "\n",
    "\n",
    "print('Validation.............................................')\n",
    "yhat = NN.training(X_validation,Y_validation_label)\n",
    "yhat = NN.normalize(yhat)\n",
    "NN.confusion_mat(Y_validation_label,yhat)\n",
    "print(\"accuracy: :{}\".format(accuracy_score(Y_validation_label,yhat)*100) +\"%\")\n",
    "\n",
    "\n",
    "\n",
    "print('Testing.............................................')\n",
    "yhat = NN.training(X_testing,Y_testing_label)\n",
    "yhat = NN.normalize(yhat)\n",
    "NN.confusion_mat(Y_testing_label,yhat)\n",
    "NN.print_values(Y_testing_label,yhat)\n",
    "print(\"accuracy: :{}\".format(accuracy_score(Y_testing_label,yhat)*100) +\"%\")\n",
    "print(\"Mean Square Error = {}\".format(NN.error(Y_testing_label,yhat)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
