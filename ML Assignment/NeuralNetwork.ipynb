{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.metrics import confusion_matrix\n",
    "from  sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION ALOGORITHM 1: NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network is a supervised learning algortihtm which means that we provide it with input data containing the independent variables and the output data that contain dependent variable.\n",
    "\n",
    "Independent variables are:\n",
    "- GRE Scores( out of 340)\n",
    "- TOEFL Scores (out of 120)\n",
    "- University Rating ( out of 5)\n",
    "- Statement of Purpose (out of 5)\n",
    "- Letter of Recommendation Strength (out of 5)\n",
    "- Undergraduate GPA (out of 10)\n",
    "- Research Experience ( either 0 or 1)\n",
    "\n",
    "\n",
    "Dependent varibale:\n",
    "- Chance of acceptance (feature that we would like to predict, 1 for accepted and 0 for rejected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GREScore</th>\n",
       "      <th>TOEFLScore</th>\n",
       "      <th>UniversityRating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>ChanceOfAdmit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GREScore  TOEFLScore  UniversityRating  SOP  LOR   CGPA  \\\n",
       "0             1       337         118                 4  4.5   4.5  9.65   \n",
       "1             2       324         107                 4  4.0   4.5  8.87   \n",
       "2             3       316         104                 3  3.0   3.5  8.00   \n",
       "3             4       322         110                 3  3.5   2.5  8.67   \n",
       "4             5       314         103                 2  2.0   3.0  8.21   \n",
       "..          ...       ...         ...               ...  ...   ...   ...   \n",
       "395         396       324         110                 3  3.5   3.5  9.04   \n",
       "396         397       325         107                 3  3.0   3.5  9.11   \n",
       "397         398       330         116                 4  5.0   4.5  9.45   \n",
       "398         399       312         103                 3  3.5   4.0  8.78   \n",
       "399         400       333         117                 4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  ChanceOfAdmit  \n",
       "0           1           0.92  \n",
       "1           1           0.76  \n",
       "2           1           0.72  \n",
       "3           1           0.80  \n",
       "4           0           0.65  \n",
       "..        ...            ...  \n",
       "395         1           0.82  \n",
       "396         1           0.84  \n",
       "397         1           0.91  \n",
       "398         0           0.67  \n",
       "399         1           0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'Admission_Predict.csv' \n",
    "df = pandas.read_csv(data_file) #reading our data file\n",
    "\n",
    "df #our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSING AND PROCESSING OUR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  , 337.  , 118.  , ...,   9.65,   1.  ,   0.92],\n",
       "       [  2.  , 324.  , 107.  , ...,   8.87,   1.  ,   0.76],\n",
       "       [  3.  , 316.  , 104.  , ...,   8.  ,   1.  ,   0.72],\n",
       "       ...,\n",
       "       [398.  , 330.  , 116.  , ...,   9.45,   1.  ,   0.91],\n",
       "       [399.  , 312.  , 103.  , ...,   8.78,   0.  ,   0.67],\n",
       "       [400.  , 333.  , 117.  , ...,   9.66,   1.  ,   0.95]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values #converting our dataframe into an array\n",
    "dataset#our array of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature data: \n",
      " [[337.   118.     4.   ...   4.5    9.65   1.  ]\n",
      " [324.   107.     4.   ...   4.5    8.87   1.  ]\n",
      " [316.   104.     3.   ...   3.5    8.     1.  ]\n",
      " ...\n",
      " [330.   116.     4.   ...   4.5    9.45   1.  ]\n",
      " [312.   103.     3.   ...   4.     8.78   0.  ]\n",
      " [333.   117.     4.   ...   4.     9.66   1.  ]]\n",
      "labelled data: \n",
      " [0.92 0.76 0.72 0.8  0.65 0.9  0.75 0.68 0.5  0.45 0.52 0.84 0.78 0.62\n",
      " 0.61 0.54 0.66 0.65 0.63 0.62 0.64 0.7  0.94 0.95 0.97 0.94 0.76 0.44\n",
      " 0.46 0.54 0.65 0.74 0.91 0.9  0.94 0.88 0.64 0.58 0.52 0.48 0.46 0.49\n",
      " 0.53 0.87 0.91 0.88 0.86 0.89 0.82 0.78 0.76 0.56 0.78 0.72 0.7  0.64\n",
      " 0.64 0.46 0.36 0.42 0.48 0.47 0.54 0.56 0.52 0.55 0.61 0.57 0.68 0.78\n",
      " 0.94 0.96 0.93 0.84 0.74 0.72 0.74 0.64 0.44 0.46 0.5  0.96 0.92 0.92\n",
      " 0.94 0.76 0.72 0.66 0.64 0.74 0.64 0.38 0.34 0.44 0.36 0.42 0.48 0.86\n",
      " 0.9  0.79 0.71 0.64 0.62 0.57 0.74 0.69 0.87 0.91 0.93 0.68 0.61 0.69\n",
      " 0.62 0.72 0.59 0.66 0.56 0.45 0.47 0.71 0.94 0.94 0.57 0.61 0.57 0.64\n",
      " 0.85 0.78 0.84 0.92 0.96 0.77 0.71 0.79 0.89 0.82 0.76 0.71 0.8  0.78\n",
      " 0.84 0.9  0.92 0.97 0.8  0.81 0.75 0.83 0.96 0.79 0.93 0.94 0.86 0.79\n",
      " 0.8  0.77 0.7  0.65 0.61 0.52 0.57 0.53 0.67 0.68 0.81 0.78 0.65 0.64\n",
      " 0.64 0.65 0.68 0.89 0.86 0.89 0.87 0.85 0.9  0.82 0.72 0.73 0.71 0.71\n",
      " 0.68 0.75 0.72 0.89 0.84 0.93 0.93 0.88 0.9  0.87 0.86 0.94 0.77 0.78\n",
      " 0.73 0.73 0.7  0.72 0.73 0.72 0.97 0.97 0.69 0.57 0.63 0.66 0.64 0.68\n",
      " 0.79 0.82 0.95 0.96 0.94 0.93 0.91 0.85 0.84 0.74 0.76 0.75 0.76 0.71\n",
      " 0.67 0.61 0.63 0.64 0.71 0.82 0.73 0.74 0.69 0.64 0.91 0.88 0.85 0.86\n",
      " 0.7  0.59 0.6  0.65 0.7  0.76 0.63 0.81 0.72 0.71 0.8  0.77 0.74 0.7\n",
      " 0.71 0.93 0.85 0.79 0.76 0.78 0.77 0.9  0.87 0.71 0.7  0.7  0.75 0.71\n",
      " 0.72 0.73 0.83 0.77 0.72 0.54 0.49 0.52 0.58 0.78 0.89 0.7  0.66 0.67\n",
      " 0.68 0.8  0.81 0.8  0.94 0.93 0.92 0.89 0.82 0.79 0.58 0.56 0.56 0.64\n",
      " 0.61 0.68 0.76 0.86 0.9  0.71 0.62 0.66 0.65 0.73 0.62 0.74 0.79 0.8\n",
      " 0.69 0.7  0.76 0.84 0.78 0.67 0.66 0.65 0.54 0.58 0.79 0.8  0.75 0.73\n",
      " 0.72 0.62 0.67 0.81 0.63 0.69 0.8  0.43 0.8  0.73 0.75 0.71 0.73 0.83\n",
      " 0.72 0.94 0.81 0.81 0.75 0.79 0.58 0.59 0.47 0.49 0.47 0.42 0.57 0.62\n",
      " 0.74 0.73 0.64 0.63 0.59 0.73 0.79 0.68 0.7  0.81 0.85 0.93 0.91 0.69\n",
      " 0.77 0.86 0.74 0.57 0.51 0.67 0.72 0.89 0.95 0.79 0.39 0.38 0.34 0.47\n",
      " 0.56 0.71 0.78 0.73 0.82 0.62 0.96 0.96 0.46 0.53 0.49 0.76 0.64 0.71\n",
      " 0.84 0.77 0.89 0.82 0.84 0.91 0.67 0.95]\n"
     ]
    }
   ],
   "source": [
    "#Here we split our dataset into input features X and the feature we wish to predict\n",
    "\n",
    "X = dataset[:,1:8] #here we remove the first column and take the remaining dataset with the exception of the feture we want to predict\n",
    "Y_ = dataset[:,8] #get our feature that we need to predict\n",
    "\n",
    "print(\"feature data: \\n\", X)\n",
    "print(\"labelled data: \\n\",Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERTING ACCEPTANCE CHANCE TO CLASSIFICATION THROUGH ROUNDING UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [] #list to store new rounded up acceptance chance column values\n",
    "threshold = 0.5 # our threshold for rounding\n",
    "\n",
    "#convert values to 0 = not accepted and 1 = accepted\n",
    "\n",
    "for i in Y_: #loop through label data \n",
    "    if i < threshold:\n",
    "        i = 0 #set to 0 \n",
    "        Y.append(i) #store updated values\n",
    "    \n",
    "    else:\n",
    "        i = 1  #otherwise set to 1\n",
    "        Y.append(i) #store updated values\n",
    "Y = np.array(Y)\n",
    "Y = Y.reshape(X.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X scaled: \n",
      " [[0.94       0.92857143 0.75       ... 0.875      0.91346154 1.        ]\n",
      " [0.68       0.53571429 0.75       ... 0.875      0.66346154 1.        ]\n",
      " [0.52       0.42857143 0.5        ... 0.625      0.38461538 1.        ]\n",
      " ...\n",
      " [0.8        0.85714286 0.75       ... 0.875      0.84935897 1.        ]\n",
      " [0.44       0.39285714 0.5        ... 0.75       0.63461538 0.        ]\n",
      " [0.86       0.89285714 0.75       ... 0.75       0.91666667 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#here we process our data to make sure that the scale of the input features are similar\n",
    "#we do this to avoid difficulties for the initialization of the neutral network\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X) #Scaling the dataset so that all input features lie between 0 and 1 inclusive\n",
    "print(\"X scaled: \\n\",X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIVIDING THE DATA\n",
    "\n",
    "7 features\n",
    "\n",
    "- X-training data = 204 (60%)\n",
    "- X- validation data = 68 (20%)\n",
    "- X- testing data = 68 (20%)\n",
    "\n",
    "Chance of admission feature\n",
    "\n",
    "- Y-training data = 204 (60%)\n",
    "- Y- validation data = 68 (20%)\n",
    "- Y- testing data = 68 (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Shape of training data:  (240, 7)\n",
      "Shape of training label:  (240, 1)\n",
      "Shape of validation data:  (80, 7)\n",
      "Shape of validation label:  (80, 1)\n",
      "Shape of testing data:  (80, 7)\n",
      "Shape of testing label:  (80, 1)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# validation and testing takes 40% of the original data and training takes 60% and randomizing\n",
    "X_training,X_validation_test, Y_training_label, Y_validation_test =  train_test_split(X_scale, Y, test_size = 0.4,random_state = 2) # here we split trainig data and validation/testing data into two\n",
    "\n",
    "#spliting validation and testing and randomizing\n",
    "\n",
    "X_validation, X_testing, Y_validation_label, Y_testing_label = train_test_split(X_validation_test,Y_validation_test,test_size = 0.5,random_state = 2)\n",
    "\n",
    "#standardize the dataset\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Shape of training data: \",X_training.shape)\n",
    "print(\"Shape of training label: \",Y_training_label.shape)\n",
    "print(\"Shape of validation data: \",X_validation.shape)\n",
    "print(\"Shape of validation label: \",Y_validation_label.shape)\n",
    "print(\"Shape of testing data: \",X_testing.shape)\n",
    "print(\"Shape of testing label: \",Y_testing_label.shape)\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.............................................\n",
      "confusion matrix\n",
      "--------\n",
      "|4 | 18|\n",
      "|1 | 217|\n",
      "--------\n",
      "accuracy: :92.08333333333333%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation.............................................\n",
      "confusion matrix\n",
      "--------\n",
      "|1 | 8|\n",
      "|0 | 71|\n",
      "--------\n",
      "accuracy: :90.0%\n",
      "Testing.............................................\n",
      "confusion matrix\n",
      "--------\n",
      "|0 | 2|\n",
      "|0 | 78|\n",
      "--------\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :0\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :1\n",
      "Predicted values : :1 | Actual values : :0\n",
      "Predicted values : :1 | Actual values : :1\n",
      "accuracy: :97.5%\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet():\n",
    "        #class takes in list that stores our network architecture, learning rate and iterations\n",
    "        # layers[7 input features, 8 nodes for hidden layer, 1 output]\n",
    "        \n",
    "        def __init__(self, layers = [7,8,1], learning_rate = 0.001, iterations = 100):\n",
    "            self.params = {} #dictionary to store weights\n",
    "            self.learning_rate = learning_rate\n",
    "            self.iterations = iterations\n",
    "            self.loss = []\n",
    "            self.sample_size  = None\n",
    "            self.layers = layers \n",
    "            self.X = None\n",
    "            self.Y = None\n",
    "        \n",
    "        #initializes weights for the network\n",
    "        #we use unifrom distribution for our weights and store them in the params dictionary \n",
    "        def init_weights(self):\n",
    "            \n",
    "            np.random.seed(1) #seed that random number of generator\n",
    "            self.params['W1'] = np.random.randn(self.layers[0], self.layers[1]) #array of shape(7,8)\n",
    "            self.params['b1'] = np.random.randn(self.layers[1],) #vector of size 8\n",
    "            self.params['W2'] = np.random.randn(self.layers[1], self.layers[2]) #array of shape(8,1)\n",
    "            self.params['b2'] = np.random.randn(self.layers[2],)#vector of size 1, the output\n",
    "            \n",
    "        #for our network we will use an activation function (ReLU function) for hidden layer\n",
    "        #This function compares a value with zero then return the value passed to if if it is greater that zero\n",
    "        #It will perform threshold operation to each value input\n",
    "        \n",
    "        def ReLU(self,Z):\n",
    "            return np.maximum(0,Z)\n",
    "        \n",
    "        #we will also use sigmoid function for our ouput layer\n",
    "        #takes in input value and squashes it to a real valued output between 0 and 1\n",
    "        \n",
    "        def sigmoid(self, Z):\n",
    "            return 1.0/(1.0 + np.exp(-Z))\n",
    "        \n",
    "        #here we gonna have a function for loss function\n",
    "        # it measures how good our neural network is predicting so that it can adjust the weights\n",
    "        \n",
    "        def entropy_loss(self,y, y_hat):\n",
    "            nsample = len(y)\n",
    "            loss = -1/nsample * (np.sum(np.multiply(np.log(y_hat),y) + np.multiply((1 - y), np.log(1 - y_hat))))\n",
    "            return loss\n",
    "        \n",
    "        \n",
    "            \n",
    "        #forward propagation\n",
    "        def forward_propagation(self):\n",
    "            \n",
    "            #perfom all dot product and addition usinf weights and biases\n",
    "            \n",
    "            Z1 = self.X.dot(self.params['W1']) + self.params['b1']  #weighted sum between input and first layer's weights and add bias\n",
    "            A1 = self.ReLU(Z1) # passing Z1 into activation function\n",
    "            Z2 = A1.dot(self.params['W2']) + self.params['b2'] #weighted sum between output of A1 and second layer's weights and add bias\n",
    "            yhat = self.sigmoid(Z2) #passing Z2 into activation function\n",
    "            loss = self.entropy_loss(self.y,yhat) #loss between predicted output and sigmoid resulyHat\n",
    "            \n",
    "            #save all calculated parameters\n",
    "            \n",
    "            self.params['Z1'] = Z1\n",
    "            self.params['Z2'] = Z2\n",
    "            self.params['A1'] = A1\n",
    "            \n",
    "            return yhat,loss #return predicted value and loss that we will use in backpropagation\n",
    "        \n",
    "            #backpropagtion to train our network by updating weights and biases\n",
    "            \n",
    "\n",
    "        def back_prop(self,yhat):\n",
    "\n",
    "            #compute derivative\n",
    "            def dReLU(x):\n",
    "                x[x <=0 ] = 0\n",
    "                x[x > 0 ] = 1\n",
    "                return x\n",
    "\n",
    "         #dl_wrt means loss with respect to \n",
    "            dl_wrt_yhat = -(np.divide(self.y,yhat) - np.divide((1 - self.y),(1-yhat))) \n",
    "            dl_wrt_sig = yhat * (1-yhat)\n",
    "            dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "            dl_wrt_A1 = dl_wrt_z2.dot(self.params['W2'].T)\n",
    "            dl_wrt_w2 = self.params['A1'].T.dot(dl_wrt_z2)\n",
    "            dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0)\n",
    "\n",
    "            dl_wrt_z1 = dl_wrt_A1 * dReLU(self.params['Z1'])\n",
    "            dl_wrt_w1 = self.X.T.dot(dl_wrt_z1)\n",
    "            dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0)\n",
    "\n",
    "            #update weights and bias\n",
    "\n",
    "            self.params['W1'] = self.params['W1'] - self.learning_rate * dl_wrt_w1 \n",
    "            self.params['b1'] = self.params['b1'] - self.learning_rate * dl_wrt_b1\n",
    "            self.params['W2'] = self.params['W2'] - self.learning_rate * dl_wrt_w2 \n",
    "            self.params['b2'] = self.params['b2'] - self.learning_rate * dl_wrt_b2\n",
    "\n",
    "        #function for prediction\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            \n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "            for i in range(self.iterations):\n",
    "                yhat, loss = self.forward_propagation()\n",
    "                self.back_prop(yhat)\n",
    "                self.loss.append(loss)\n",
    "                \n",
    "            return yhat\n",
    "\n",
    "\n",
    "        def predict(self, X):\n",
    "            \n",
    "            Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "            A1 = self.ReLU(Z1)\n",
    "            Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "            pred = self.sigmoid(Z2)\n",
    "            return np.round(pred)              \n",
    "\n",
    "\n",
    "        def plot_loss(self):\n",
    "\n",
    "            plt.plot(self.loss)\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"logloss\")\n",
    "            plt.title(\"Loss curve for training\")\n",
    "            plt.show()\n",
    "            \n",
    "        def confusion_mat(self, actual, predicted):\n",
    "            cm = confusion_matrix(actual,np.round(predicted))\n",
    "            print(\"confusion matrix\")\n",
    "            print(\"--------\")\n",
    "            print(\"|\" + str(cm[0][0]) + \" | \" + str(cm[0][1]) + \"|\")\n",
    "            print(\"|\" + str(cm[1][0]) + \" | \" + str(cm[1][1]) + \"|\")\n",
    "            print (\"--------\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        def normalize(self, arr):\n",
    "            new_arr = []\n",
    "            threshold = 0.5 # our threshold for rounding\n",
    "\n",
    "            #convert values to 0 = not accepted and 1 = accepted\n",
    "\n",
    "            for i in arr: #loop through label data \n",
    "                if i < threshold:\n",
    "                    i = 0 #set to 0 \n",
    "                    new_arr.append(i) #store updated values\n",
    "\n",
    "                else:\n",
    "                    i = 1  #otherwise set to 1\n",
    "                    new_arr.append(i) #store updated values\n",
    "            new_arr = np.array(new_arr)\n",
    "            return new_arr\n",
    "        \n",
    "        def print_values(self, actual, predicted):\n",
    "            \n",
    "            for i in range(1,len(actual)):\n",
    "                print(\"Predicted values : :{}\".format(predicted[i]) + \" | \" + \"Actual values : :{}\".format(actual[i][0]))\n",
    "            \n",
    "            \n",
    "            \n",
    "NN = NeuralNet()\n",
    "\n",
    "\n",
    "\n",
    "print('Training.............................................')\n",
    "yhat = NN.fit(X_training,Y_training_label)\n",
    "yhat = NN.normalize(yhat)\n",
    "NN.confusion_mat(Y_training_label,yhat)\n",
    "print(\"accuracy: :{}\".format(accuracy_score(Y_training_label,yhat)*100) +\"%\")\n",
    "NN.plot_loss()\n",
    "\n",
    "\n",
    "print('Validation.............................................')\n",
    "yhat = NN.fit(X_validation,Y_validation_label)\n",
    "yhat = NN.normalize(yhat)\n",
    "NN.confusion_mat(Y_validation_label,yhat)\n",
    "print(\"accuracy: :{}\".format(accuracy_score(Y_validation_label,yhat)*100) +\"%\")\n",
    "\n",
    "\n",
    "\n",
    "print('Testing.............................................')\n",
    "yhat = NN.fit(X_testing,Y_testing_label)\n",
    "yhat = NN.normalize(yhat)\n",
    "NN.confusion_mat(Y_testing_label,yhat)\n",
    "NN.print_values(Y_testing_label,yhat)\n",
    "print(\"accuracy: :{}\".format(accuracy_score(Y_testing_label,yhat)*100) +\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
